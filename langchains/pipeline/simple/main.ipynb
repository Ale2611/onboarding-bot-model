{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Get Started](https://python.langchain.com/docs/expression_language/get_started)\n",
    "- [Retrieval](https://python.langchain.com/docs/expression_language/cookbook/retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Token from File \n",
    "*⚠️ Add `TOKEN.txt` to .gitignore* \n",
    "\n",
    "Create a GitHub Token using this [Link](https://github.com/settings/tokens/new) and configure it with the following parameters:\n",
    "* `read:packages`\n",
    "* `read:org`\n",
    "* `read:discussion`\n",
    "* `read:project`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = open('TOKEN.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file strapi has been successfully downloaded.\n",
      "The file strapiv4 has been successfully downloaded.\n",
      "Failed to download the file dev-launchers-platform.\n",
      "Failed to download the file react-course-finals.\n",
      "Failed to download the file discord-gateway.\n",
      "Failed to download the file auth-proxy.\n",
      "The file onboarding-bot-model has been successfully downloaded.\n",
      "The file webhook-workers has been successfully downloaded.\n",
      "Failed to download the file VictorDiniz89.\n",
      "The file onboarding-bot has been successfully downloaded.\n",
      "The file platform__dl-edu has been successfully downloaded.\n",
      "The file minecraft__dev-launchers-library has been successfully downloaded.\n",
      "The file community-minecraft has been successfully downloaded.\n",
      "Failed to download the file stories.\n",
      "Failed to download the file monorepo.\n",
      "Failed to download the file platform__dl-ideas.\n",
      "The file project__mhw-guides has been successfully downloaded.\n",
      "The file devbots__general has been successfully downloaded.\n",
      "Failed to download the file Dev-Recruiters.\n",
      "The file cron-worker has been successfully downloaded.\n",
      "The file devbots__game has been successfully downloaded.\n",
      "Failed to download the file dashboard.\n",
      "Failed to download the file site-projects.\n",
      "The file platform__dev-env has been successfully downloaded.\n",
      "Failed to download the file Dev-Mentors.\n",
      "The file devbots__backend has been successfully downloaded.\n",
      "Failed to download the file site-users.\n",
      "The file minecraft__tamingplus has been successfully downloaded.\n",
      "The file project__oj has been successfully downloaded.\n",
      "The file website-router has been successfully downloaded.\n",
      "The file minecraft__newbies has been successfully downloaded.\n",
      "Failed to download the file minecraft__dailies.\n",
      "The file minecraft__egg-hunt has been successfully downloaded.\n",
      "The file minecraft__pack has been successfully downloaded.\n",
      "The file project__recipe-book has been successfully downloaded.\n",
      "The file minecraft__devbeans has been successfully downloaded.\n",
      "The file minecraft__travelers-wand has been successfully downloaded.\n",
      "Failed to download the file minecraft__guardians.\n",
      "Failed to download the file InfoActionBar_Plugin-Minecraft.\n",
      "The file community-minecraft-plugins has been successfully downloaded.\n",
      "The file learning-resources has been successfully downloaded.\n",
      "The file community-engagement__general has been successfully downloaded.\n",
      "Failed to download the file private__website.\n",
      "Failed to download the file react-bookstore-cart.\n",
      "Failed to download the file mongodb-backup.\n",
      "Failed to download the file interactive-bot.\n",
      "Failed to download the file app-proxy.\n",
      "Failed to download the file project__posted-backend.\n",
      "Failed to download the file tool__admin-portal.\n",
      "Failed to download the file project__discord-bot.\n",
      "Failed to download the file project__allone.\n",
      "Failed to download the file project__posted.\n",
      "Failed to download the file project__sports-area.\n",
      "Failed to download the file project__safe-keep.\n",
      "Failed to download the file project__forest-favors.\n",
      "Failed to download the file project__pokemon-for-dummies.\n",
      "Failed to download the file tool__slack-bridge.\n",
      "Failed to download the file tool__slack-file-share.\n",
      "Failed to download the file project__On-A-Mission.\n",
      "Failed to download the file project__pong-adventure.\n",
      "Failed to download the file project__poddles.\n",
      "Failed to download the file project__hungry-ghost.\n",
      "Failed to download the file template__activity.\n",
      "Failed to download the file template__project.\n"
     ]
    }
   ],
   "source": [
    "org_name = 'dev-launchers'\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_organization_repositories(org_name, access_token):\n",
    "    headers = {\n",
    "        'Authorization': f'token {access_token}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'sort': 'updated',\n",
    "        'direction': 'desc',\n",
    "        'per_page': 100\n",
    "    }\n",
    "\n",
    "    # Retrieve the list of repositories for the organization\n",
    "    response = requests.get(f'https://api.github.com/orgs/{org_name}/repos', headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        repositories = response.json()\n",
    "        return repositories\n",
    "    else:\n",
    "        print(f'Error {response.status_code}: Unable to retrieve organization repositories.')\n",
    "        return None\n",
    "\n",
    "repositories = get_organization_repositories(org_name, access_token)\n",
    "\n",
    "repo_readme_list = []\n",
    "\n",
    "if repositories:\n",
    "    for repo in repositories:\n",
    "        # Create Links\n",
    "        repo_readme = repo['html_url'].replace(\"https://github.com\", \"https://raw.githubusercontent.com\") + \"/main/README.md\"\n",
    "        # Adding to List\n",
    "        repo_readme_list.append(repo_readme)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def download_files(urls, folder_name=\"Folder\"):\n",
    "    # Create the folder if it does not exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for url in urls:\n",
    "        # Get the file name from the URL\n",
    "        file_name = url.split(\"/\")[-3]\n",
    "        \n",
    "        # Concatenate the full file path\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "        # Download the file\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Write the content into the local file\n",
    "            with open(f\"{file_path}.md\", 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"The file {file_name} has been successfully downloaded.\")\n",
    "        else:\n",
    "            print(f\"Failed to download the file {file_name}.\")\n",
    "\n",
    "\n",
    "download_files(repo_readme_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2666.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "# Load Files \n",
    "loader = DirectoryLoader('../', glob=\"**/*.md\", loader_cls=TextLoader, show_progress=True, use_multithreading=True)\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "# Split Markdowns by titles and subtitles \n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "docs = []\n",
    "\n",
    "for document in documents:\n",
    "    docs.extend(markdown_splitter.split_text(document.page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "#retriever = vectorstore.as_retriever()\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1}) # Limit to First top document correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- https://python.langchain.com/docs/integrations/chat/huggingface\n",
    "- https://python.langchain.com/docs/integrations/llms/huggingface_pipelines#create-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# model_id = \"databricks/dolly-v2-3b\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=10)\n",
    "# hf = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "hf = HuggingFaceHub(repo_id=\"databricks/dolly-v2-3b\", \n",
    "                    model_kwargs={\"temperature\": 0.5, \n",
    "                                  \"max_new_tokens\": 64},\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/expression_language/get_started\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | hf | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How install huggingface hub\"\n",
    "\n",
    "truc = chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Answer the question based only on the following context:\\n[Document(page_content='```shell\\\\npip install huggingface_hub\\\\npip install transformers\\\\n```', metadata={'Header 1': 'Install'})]\\n\\nQuestion: How install huggingface hub\\n\\nAnswer: pip install huggingface_hub\\n\\nDocument 2:\\n[Document(page_content='```shell\\\\npip install huggingface_hub\\\\npip install transformers\\\\n```', metadata={'Header 1': 'Install'})]\\n\\nQuestion: How install huggingface\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
