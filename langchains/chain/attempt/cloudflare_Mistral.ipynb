{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS as VectorStore\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "embeddings = GPT4AllEmbeddings()\n",
    "store = VectorStore.load_local(\"../../retrieve/vector_store\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = store.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "my_account_id = getpass.getpass(\"Enter your Cloudflare account ID:\\n\\n\")\n",
    "my_api_token = getpass.getpass(\"Enter your Cloudflare API token:\\n\\n\")\n",
    "llm_model = \"@hf/mistralai/mistral-7b-instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.cloudflare_workersai import CloudflareWorkersAI\n",
    "\n",
    "llm = CloudflareWorkersAI(account_id=my_account_id, api_token=my_api_token, model=llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains\n",
    "https://python.langchain.com/docs/modules/memory/adding_memory_chain_multiple_inputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "\n",
    "Given the following extracted parts of a long document and a question, create a final answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")\n",
    "\n",
    "chain = load_qa_chain(llm=llm, chain_type=\"stuff\", memory=memory, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 10 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content=\"The chatbots are in their respective folders with an application launcher `autorun.sh` to install each of them without specific knowledge.  \\nOn Mac, open the terminal and type:\\n```shell\\ncd\\n```\\nDrag the **`folder`** containing the file `autorun.sh`, then press the Enter key (↩︎).  \\n_If you have done it correctly, the **`~`** between your machine's name (`name@MacBook-Pro-of-Name`) and the **`%`** sign should display the name of the `folder` instead._  \\nExecute the following line of code by pressing the Enter key (↩︎):\\n```shell\\nsh autorun.sh\\n```\\nWait a moment, the model should open in your default web browser.\", metadata={'Header 1': 'Models', 'Header 2': 'Installation', 'Header 3': 'Streamlit & FastAPI'}),\n",
       "  Document(page_content='The subfolders listed below contain key steps in our research for creating a functional, convenient, and maintainable chatbot.', metadata={'Header 1': 'Onboarding Bot Model', 'Header 2': 'Structure'}),\n",
       "  Document(page_content='Development of the current [chatbot](https://github.com/dev-launchers/onboarding-bot) by the team, utilizing the [ChatGPT API](https://platform.openai.com/docs/api-reference).  \\nThe [models](../models) folder contains open-source [LLMs](https://en.wikipedia.org/wiki/Large_language_model) are being tested with the aim of including the best among them in the [RAG](../langchains/LANGCHAINS.md) we are going to set up. You can try out the different pre-installed language models in the subfolders named after them in the `models` directory.', metadata={'Header 1': 'Models', 'Header 2': 'Overview'}),\n",
       "  Document(page_content=\"1. make sure your file structure looks like this\\n```\\n├── plaform__api\\n├── platform__dev-env\\n├── project__discord-bot\\n```\\n2. Make sure to add all the env var to the `api.env.example`. After adding all the env var,\\nmake sure to remove .example from `api.env.example`. It should look like this `api.env`.\\nIf you don't know the env var, just ask in the backend-chat channel on discord and someone\\nshould send you all the env vars.\", metadata={'Header 1': 'Setup'})],\n",
       " 'human_input': 'How install the chatbots',\n",
       " 'chat_history': '',\n",
       " 'output_text': ' To install the chatbots, follow these steps:\\n\\n1. Open the Terminal on your Mac.\\n2. Type `cd` and press Enter to navigate to your home directory.\\n3. Drag the folder containing the `autorun.sh` file into the terminal and press Enter. The name of the folder should appear instead of the `~`.\\n4. Execute the following line of code by pressing Enter: `sh autorun.sh`\\n5. Wait for the model to open in your default web browser.\\n\\nThe subfolders in the folder contain the steps for creating a functional, convenient, and maintainable chatbot. The `models` folder contains open-source Language Models (LLMs) that are being tested for inclusion in the RAG (Refer to LANGCHAINS.md). You can try out the different pre-installed language models in the subfolders named after them in the `models` directory.\\n\\nBefore installing, make sure your file structure looks like this:\\n```\\n├── platform__api\\n├── platform__dev-env\\n├── project__discord-bot\\n```\\n\\nAfter installing, make sure to add all'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "query = \"How install the chatbots\"\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "chain.invoke({\"input_documents\": docs, \"human_input\": query}) #, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some interesting documents\n",
    "\n",
    " https://python.langchain.com/docs/get_started/quickstart/#conversation-retrieval-chain \\\n",
    " https://python.langchain.com/docs/use_cases/chatbots/quickstart/ \\\n",
    " https://python.langchain.com/docs/use_cases/chatbots/retrieval/ \\\n",
    " https://python.langchain.com/v0.1/docs/integrations/llms/cloudflare_workersai/ \n",
    " https://api.python.langchain.com/en/latest/llms/langchain_community.llms.cloudflare_workersai.CloudflareWorkersAI.html\n",
    "\n",
    "#### default in CloudFlare documentation \n",
    "```python\n",
    "llm_model = \"@cf/meta/llama-2-7b-chat-int8\" \n",
    "```\n",
    "#### default in HuggingFace deploy buton \n",
    "```python\n",
    "llm_model = \"@hf/mistralai/mistral-7b-instruct-v0.2\" \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
